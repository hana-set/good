---
title:  "0.Elementary"
excerpt: "분석에 기초적인 내용들에 대해 알아보자."
categories:
  - Py_Analysis
tags:
  - 기초
last_modified_at: 2021-02-07

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true
---

```python
from IPython.display import Image 
from IPython.core.display import HTML 
```


```python
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
data=sns.load_dataset('iris')
```

# 데이터 나누기

- 성능 평가를 위해 데이터를 Train 과 test 로 나눠야 한다.
- 대게 공모전시에는 주어진 set 에 대해서 train 과 validation set 으로 나눈 뒤에 진행한다.

## Train/Test set 분할


```python
data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal_length</th>
      <th>sepal_width</th>
      <th>petal_length</th>
      <th>petal_width</th>
      <th>species</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
  </tbody>
</table>
</div>



- 위 set 에서 species 가 우리의 Target 변수라고 하자.


```python
y =data['species'] # Y target 을 species 로 잡겠다.(classification)
X =data.drop('species',axis=1) # x 변수는 species 를 제외한 나머지
```

- 이제 sklearn 의 model_selection 에서 train_test_split 을 이용하면 train 과 test 를 분할할 수 있다.
- 분할시에 주의해야할 것은 random state 를 고정해야 재현성을 확보할 수 있다는 것이다.
- X_train, X_test, y_train, y_test 의 순서를 잘 지키자.
- 대게 test set 의 size 는 0.2 로 잡는다. 


```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.8, random_state=42)
```

# classification 성능평가

- Classification 의 성능에는 다양한

## confusion_matrix(y_true, y_pred)

confusion matrix : 정답 클래스는 행(row)으로 예측한 클래스는 열(column)로 나타낸다. <br>
- 즉 diagonal 에 있는 수는 예측을 잘 한 경우이다
- 사이킷런 패키지에서 제공하는 confusion_matrix 명령을 사용할 때는 클래스 순서가 0, 1, 2, ... 순서로 출력되기때문에 주의하자


```python
y_true = [1, 1, 2, 3, 3, 3, 3]
y_pred = [1, 1, 2, 2, 2, 3, 3]
```


```python
from sklearn.metrics import confusion_matrix
confusion_matrix(y_true, y_pred)
```




    array([[2, 0, 0],
           [0, 1, 0],
           [0, 2, 2]], dtype=int64)



즉 참값이 3 일때에 이 모델은 예측을 못 하고 있음을 볼 수 있다.

## accuracy_score(y_true, y_pred)

정확도(accuracy)는 전체 샘플 중 맞게 예측한 샘플 수의 비율을 뜻한다. 높을수록 좋은 모형이다. 일반적으로 학습에서 최적화 목적함수로 사용된다


```python
y_true = [1, 1, 2, 2, 2]
y_pred = [1, 1, 2, 2, 3]
```


```python
from sklearn.metrics import accuracy_score
accuracy_score(y_true,y_pred)
```




    0.8



## precision_score(y_true, y_pred)

A class 라고 예측한 것들 중 실제로 A class 인 것의 비율

그래서 TEST 의" '정확도' score 라고 한다.

hyper parameter 

- macro: 단순평균
- weighted: 각 클래스에 속하는 표본의 갯수로 가중평균


```python
y_true = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]

y_pred = [1, 1, 1, 2, 2, 1, 2, 2, 2, 3]
```


```python
# averge =None 을 해야 multi label 에서 작동한다.
# 원래 precision_score 는 이진분류 (양성,음성) 에서 만들어진 score 라 지금경우 label 이 3개인 경우 3개의 값을 나타낸가.
from sklearn.metrics import precision_score
precision_score(y_true,y_pred,average=None)
```




    array([0.75, 0.4 , 1.  ])




```python
precision_score(y_true,y_pred,average='weighted')
```




    0.745



## recall_score(y_true, y_pred)

실제 A 클래스에 속한 표본 중에 A 클래스에 속한다고 출력한 표본의 수의 비율을 뜻한다.

그래서 test 의 '재현율' 이라고 한다. 실제 클래스의 값들을 모두 뽑아내는지에 대한 score 이다.


```python
from sklearn.metrics import recall_score
recall_score(y_true,y_pred,average=None)
```




    array([1.        , 0.66666667, 0.25      ])




```python
recall_score(y_true,y_pred,average='weighted')
```




    0.6



## F1_score(y_true, y_pred)

정밀도와 재현율의 가중조화평균(weight harmonic average)을 F점수(F-score)라고 한다.

F1 score는 데이터 label이 불균형 구조일 때, 모델의 성능을 정확하게 평가할 수 있으며, 성능을 하나의 숫자로 표현할 수 있습니다

베타가 1인 경우를 특별히 F1점수라고 한다. F1=2⋅precision⋅recall/(precision+recall)

높을수록 좋음


```python
y_true = [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2]

y_pred = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
```


```python
from sklearn.metrics import f1_score
f1_score(y_true,y_pred, average='weighted')
```




    0.7363636363636363




```python
y_true = [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2]

y_pred = [1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2]
```


```python
from sklearn.metrics import f1_score
f1_score(y_true,y_pred,average='weighted')
```




    0.8371212121212122




```python
# 위와 같이 틀린 횟수는 똑같지만, 적은 데이터데 대해 작 예측할때 f1 score 가 높은것을 볼 수 있습니다.
```

## classification_report(y_true, y_pred)


```python
y_true = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]

y_pred = [1, 1, 1, 2, 2, 1, 2, 2, 2, 3]
```


```python
import classification_report

class_name = ['class 1', 'class 2', 'class 3']

print( classification_report(y_true,y_pred, target_names= class_name ) )
```

                  precision    recall  f1-score   support
    
         class 1       0.75      1.00      0.86         3
         class 2       0.40      0.67      0.50         3
         class 3       1.00      0.25      0.40         4
    
        accuracy                           0.60        10
       macro avg       0.72      0.64      0.59        10
    weighted avg       0.74      0.60      0.57        10
    
    

# Regression 성능평가

# 모형 최적화(Hyperparameter)

## GridSearchCV
- Grid Search 는 Parameter search 시에 격자처럼 paramter 들의 모든 조합을 시험하고, 그 중에서 제일 좋은 성능을 보이는 paramter 를 고른다.
- 하지만 paramter 가 2개보다 커지는 순간부터 그 조합의 수가 기하급수적으로 많아지기 때문에 비효율적이다.
- 그러므로 2~3개의 parameter 를 가지는 경우에 적합하고 tree모델의 경우는 파라미터가 너무 많아 비추천한다.
- 그리고 일반적으로 Randomize search 보다 많은 지점을 편향없이 보지 못하기 때문에(사용자가 직접 보고자 하는 값들을 적어주어야함) 별로 추천하지는 않는다. 

### 단일 parameter 


```python
# 데이터 생성
from sklearn.datasets import load_boston
boston = load_boston()
X = boston.data
y = boston.target
```


```python
from sklearn.linear_model import Lasso, Ridge
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import GridSearchCV

ridge = Ridge()
alphas = np.linspace(1, 500, 200) # 추정하려는 parameter 범위
parameters = {'alpha': alphas } # 추정하려는 parameter(이때 이름은 모델의 parameter default 이름과 똑같이 넣어야 한다.)

model = GridSearchCV(estimator = ridge, param_grid = parameters, scoring='neg_mean_squared_error',cv=5)
# estimator : 모델
# param_grid : 추정하고싶은 파라미터 이름(str)을 key 로. lists of parameter settings 을 value 로 하는 dictionary
# scoring : evaluate the predictions on the test set
#         : (default) model 이 가지고있는 default evaluation criterion 를 쓴다
#         : model has score method providing a default evaluation criterion for the problem they are designed to solve 
#         : ‘accuracy’ = metrics.accuracy_score (classification)
#         : ‘r2’ = metrics.r2_score (regression)
#         : ‘neg_mean_squared_error’ : metrics.mean_squared_error (regression)
#         : 자세한건 scoring parameter 
# cv : k-fold validation 에서 k
#    : (default)3-fold cross validation
model.fit(X,y)
# fitting 을 해야 위에서 설정한 객체가 그대로 적용이 되면서 비로소 best 한 parameter 를 찾아준다.

print(model.best_params_) # 우리가 추정한 best parameter
print(model.best_score_) # 우리가 지정한 scoring 에 기반한 제일 좋은 score

```

    {'alpha': 151.45226130653265}
    -29.753677540045423
    


```python
# CV result 분석
```


```python
result = pd.DataFrame(model.cv_results_)[['param_alpha','mean_test_score']]
plt.plot('param_alpha','mean_test_score',data=result,)
```




    [<matplotlib.lines.Line2D at 0x19c8d31ddc8>]




    
<img src="/assets/images/0.Elementary/output_49_1.png">
    



```python
print(model.best_params_) # 우리가 추정한 best parameter
print(model.best_score_) # 우리가 지정한 scoring 에 기반한 제일 좋은 score
```

    {'alpha': 151.45226130653265}
    -29.753677540045423
    


```python
# (note)
# 근데 왜 mse 가 음수인가요? 
# 사이킷런의 교차 검증 기능은 scoring 매개변수에 (낮을수록 좋은) 비용 함수가 아니라 (클수록 좋은) 효용 함수를 기대합니다. 
# 그래서 평균 제곱 오차(MSE)의 반댓값(즉, 음숫값)을 계산하는 neg_mean_squared_error 함수를 사용
```

### 여러개 parameter 


```python
#데이터 생성
data=sns.load_dataset('iris')
y =data['species'] # Y target 을 species 로 잡겠다.(classification) # 이 때에 1dim array 로 해주어야한다.
X =data.drop('species',axis=1) # x 변수는 species 를 제외한 나머지
X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.8, random_state=42)
```


```python
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV

scv = SVC()
param_grid ={'C' : [0.001,0.01,0.1,1,10,100], 'gamma' : [0.001,0.01,0.1,1,10,100] }
model = GridSearchCV(scv,param_grid,cv=5)
# scoring 은 default 이므로 model 의 자체 scoring 을 이용해 최적화를 하게 된다. 
# 이제 model=GridSearchCV 는 GridSearch 를 통해 최적화된 parameter 를 이용한 scv model 이 합쳐진 것이 된다. 
model.fit(X,y)
print(model.best_params_) # 우리가 추정한 best parameter
print(model.best_score_) # 우리가 지정한 scoring 에 기반한 제일 좋은 score
```

    {'C': 1, 'gamma': 0.1}
    0.9800000000000001
    

## Randomize search

- Randomize search 는 Grid search 보다는 훨씬 낫다.
- 사람이 범위를 지정해주면 그 범위 안에서 최적값을 random 으로 search 하면서 찾아낸다.
- n_iter 을 지정한 만큼 Random search 를 진행하게 된다. 
- 하지만 여전히 paramter 가 너무 많아지면 randomize search 로도 과부하가 걸린다.
- 이 때에는 Baysian Optimization 툴을 이용하는것이 좋다.(이는 추후에 소개하도록 하겠다.)


```python
from sklearn.svm import SVC
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform
from scipy.stats import randint

scv = SVC()
param_grid ={'C' : uniform(0.001,100) , # uniform 은 paramter 가 실수값을 가져야 할 때에 유용하다.
             'gamma' : randint(low=1, high=10)} # randint 는 parameter 가 정수값을 가져야 할 때에 유용하다.
model = RandomizedSearchCV(scv,param_grid,cv=5,n_iter=100)
model.fit(X,y)
print(model.best_params_) # 우리가 추정한 best parameter
print(model.best_score_) # 우리가 지정한 scoring 에 기반한 제일 좋은 score
```

    {'C': 1.1349957248947984, 'gamma': 5}
    0.9666666666666668
    

## Baysian optomization

- 이는 별도의 파일에 정리해 놓았다. 
- 아직 기초 과정에서 다룰만하지 않기 때문


```python

```
