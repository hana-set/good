---
title:  "A/B Test Mistakes"
excerpt: "A/B 에서 주의해야될점"
categories:
  - Others
tags:
  - 3
last_modified_at: 2021-03-04

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math : true
---

# 색깔의 과대평가를 하지마라

당뇨병을 관리하도록 도와주는 건강앱 CareLogger 의 예시를 보자.

![png](/assets/images/{Others}/3_1.PNG)

클릭 유도 버튼(CTA) 의 버튼 색깔을 초록색에서 빨간색으로 바꾸었을때에 34%의 높은 전환율을 보였다고 한다.

이런 '버튼의 색깔' 만 바꾸었는데 전환율이 올랐다 라는 사실은 매우 매력적으로 들린다. 크게 힘을 들이지 않고 바꿀 수 있는 부분인데다가, 그로 인한 효과도 명확해 보이기 때문이다. 하지만 단순히 여름이니 시원한 색으로 바꾸자 등의 가설은 Significant 한 결과를 얻기 힘들다.

<br>

---

# 적절한 샘플 수를 미리 계산해라

적절한 샘플 수를 고려하는것도 매우 중요하다. A/B 테스트를 하기 전에는 적절한 샘플 수 (통계적으로 어느정도 유의한 결과를 얻기 위함)를 미리 정하고 계획하는것이 중요하다.

![png](/assets/images/{Others}/3_2.PNG)

위의 경우를 보면 초기에는 초록색 그래프의 Conversion 이 높지만 , 샘플수가 늘어나면서 결과가 역전되어버린 경우를 볼 수 있다. 즉 적절한 샘플수를 미리 정해두어야 한다.

<br>

---

# 외부 변수를 적절히 고려하라

이는 상관관계와 인과관계가 다르다는 사실부터 알고 넘어가자. 어떤 실험 결과에서 아이스크림의 판매량이 높으면 북극의 빙하가 더 빨리 녹는다는 사실이 0.00001 의 p-value 로 유의하다는 결과가 나왔다고 하자. 그러면 온난화를 막기 위해서 아이스크림의 판매량을 줄여야 할까?

위의 결과는 단순히 '상관관계' 가 있을뿐 '인과관계'는 아닌 경우의 예시이다. '여름' -> '더워짐' 그에따라서 아이스크림의 판매량이 늘고, 여름이라 빙하가 더 녹았을 뿐 인과관계는 아닌것이다. 이런 상관관계와 인과관계의 차이를 늘 생각해야 한다.

6월에 디자인을 개편하였을 때에 매출이 증가하였다고 하자. 하지만 이 디자인이 영향을 주었을까? 대학생의 방학이 6월에 겹쳐있는것을 고려하면 , '대학생이 많이 접속했다' 라는 특수한 상황이 디자인의 개편보다 더 많은 영향을 주었을 수 있다. 

<br>

---

# Sample 을 무작위로 잘 나누어라.

남성을 A , 여성을 B 집단으로 나눈다거나, 짝수일 방문 : A / 홀수일 방문 : B 처럼 나눈다고 하자. 그러면 두 집단의 Population 차이로 Test 가 올바르게 이루어지지 않을것이다. 

또한 완전히 Random 일 경우에도 편향이 발생할 수 있는데, 엄청나게 소비를 많이하는 파워 컨슈머가 A/B 집단 중 A 집단에 80%나 들어가버렸다고 하자. (파워 컨슈머의 수가 매우 적을때는 가능한 시나리오 이다.) 이런 경우에는 디자인에 상관없이 A 집단이 훨씬 효과적으로 나올 수 있다. 

<br>

---

# 단순히 전환율만 높이려는게 아니다

A/B 테스트는 단순히 전환율을 높이고자 하는 실험이 아니다. '더 나은 의사결정을 위한 Insight 를 찾는것이 목적이다.' 

![png](/assets/images/{Others}/3_3.PNG)

위 언더웨어 쇼핑몰의 사례를 보자. 이미지와 함께 제품 2가지를 보여주는 배너와, 배너와 이미지 없이 좀 더 자세한 제품설명 텍스트를 보여주었을 때에 어느 배너가 전환율이 더 높은지 A/B 테스트를 진행하였다. 그 결과 소재B 가 더 높은 전환율을 보였다. 이로부터 **"언더웨어는 비슷한게 많아서 이미지보다 자세한 텍스트를 보여주었을 때 전환율이 더 높다"** 라는 인사이트를 얻을 수 있었다.

<br>

---

# 결과를 객관적으로 바라보아라.

A/B 테스트의 결과를 철저한 데이터 기반의 의사결정이 아니라 본인의 가설을 증명하려는 방향으로 결정을 내리면 안된다.

![png](/assets/images/{Others}/3_4.PNG)

아무리 공들인 프로젝트였다 할지어도, A/B 테스트의 결과를 유연하게 받아들일 수 있는 조직문화와 용기가 필요하다.

<br>

---

# A/B 테스트는 만능이 아니다.

A/B 테스트는 과학에서 오래전부터 쓰였던 대조실험을 웹/앱으로 가져온 것이다. 이를 통해서 가설을 데이터로 증명할 수 있게 되었지만 통계에 너무 집착하면 안된다.

애초에 업계뿐만 아니라, 학계에서도 P-value 를 맹신하는 경향이 있다. 그러나 이 개념을 발전시킨 피셔 조차도 P-value는 '하나의 참조점' 이 되어야 한다고 하였다. 사실 0.05 의 기준조차도 하나의 '통념' 처럼 굳어진것 뿐이지 아무런 과학적 근거가 없다. 그리고 같은 실험을 반복하게 되면 P-value 가 달라지는경우도 매우 많다. 즉 P-value 는 만능이 아니라는것이다. 

A/B 테스트를 통해 얻는것은 '어느것이 좀 더 나은가, 이 결과가 믿음직 한가?' 정도이지 절대적인 결정기준이 되어선 안된다. 테스트를 통해 얻은 인사이트를 비즈니스와 연결시키고, 성장시킬 수 있을때 A/B 테스트가 빛을 발하는 것이다.

<br>

---

# 테스트를 자주하면 단기적으로 손해가 발생할 수 있다.

구매 전환율이 높은 상품인 "해태 해감바지락"의 배너광고에 대해서 A/B 테스트를 진행한다고 해 보자. 한달동안 방문자를 50:50 으로 나누에 A/B 테스팅을 진행해 보려 한다. 그런데, 변화를 주었을때의 구매 전환율이 엄청 낮다고 해 보자. 그러면 테스팅을 오랜기간 지속할 수록 매우 큰 손해를 감수해야한다.

<br>

---

# 테스팅시에는 시간적 요소를 고려해야한다.

통제 실험은 기본적으로 시공간의 보편성을 가지고 시작한다. 이 가정은 물리/화학에서는 확실히 보장된다.(통제된 실험실에서 진행되므로) 그러나 생물학 , 사회과학 분야로 갈수록 이 가정은 약해지며 비즈니스까지로 오게 된다면 이 가정은 매우 약해진다. (겨울의 소비자와 여름의 소비자가 같을리가 없다!) 즉 확실성을 가지기 위해서는 실험을 지속적으로 해야되는데 이럴 경우 비용과 시간문제로 곤란해진다.

<br>

---

# Local Point(optimization) 으로 빠질 수 있다.

이는 딥러닝에서 learning rate 를 정할떄와 비슷하다고 보면 된다. A/B 테스팅은 기존 상태에서 작은 변화를 가하며(즉 작은 학습률) 점진적으로 최고의 매출을 찾아가는 Optimiazation 이다. 하지만 이럴경우 local 포인트에 빠질 수 있으며 global 한 최적점을 찾기 어려울 수 있다. 

<br>

---

# Reference

- http://groobee.net/2019/09/30/abtest-mistake-5/  #  GROOBBEE 마케팅 솔루션 사이트

- https://boxnwhis.kr/2015/01/29/a_b_testing.html # 박스앤위스커 강규영 기획자의 글