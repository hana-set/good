---
title:  "A/B Test"
excerpt: "A/B 테스트란?"
categories:
  - Others
tags:
  - 3
last_modified_at: 2021-03-03

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math : true

---

# 용어 정리

- 전환율/Conversion rate : 웹사이트의 방문자가 웹사이트에서 목표로 하는 액션을 완료한 비율

- Better ROI : 투자수익률

- Reduce Bounce Rate : 이탈률

  <br>

# A/B 테스트란?

- 임의로 나눈 두 집단에서 서로 다른 컨텐츠를 제시한 후, 두 집단 중 어떤 집단이 더 높은 성과를 보이는지를 평가하는 방식이다.
  - 웹사이트의 어떤 구조가 더 구매를 유도하는지 테스트 할 수 있다.
  - 버튼의 색깔을 다르게 하여, 어느 색깔이 방문자의 이목을 더 끄는지 테스트할 수 있다.
- A/B 테스트는 웹사이트 뿐만 아니라 앱, 게임환경 등 많은 부분에서 활용이 가능하지만, 이 포스팅에서는 웹사이트라고 한정하겠다.


<br>

# A/B 테스트를 왜 해야되는가

1. **Solve Visitor Pain Points**

   - 사이트의 방문자는 물건을 산다던지, 또는 상품 비교를 하고 싶다던지 등의 특정한 목적을 가지고 방문을 한다.

   - 하지만 어떠한 요인 때문에 이러한 목표를 잘 달성하지 못할 수 있다.

     - EX) 구매 결재버튼의 가시성이 좋지 않아서, 다수의 방문자들이 엉뚱한 버튼을 몇차례 누르다가 비로소 구매를 한다

     - EX) 사이트의 구조가 너무 딱딱해서 다수의 방문자가 1초만에 나가버린다.

   - 이러한 Visitor 들의 Pain Points 들을 로그분석 (클릭 위치, 수, 휠을 언제 내리는지... 등의 로그데이터를 이용)을 통해 해결할 수 있다.

2.  **Get Better ROI(투자수익률) from Existing Traffic**

   - 새로 Traffic data 를 얻는일은 매우 비용이 크다.
   - 하지만 이미 존재하는 Traffic 을 통해, A/B test 는 큰 개선점과 그에따른 수익을 기대할 수 있다.

3. **Reduce Bounce Rate (이탈률)**

   - 웹사이트의 가치를 평가하는 중요한 metric 중의 하나가 이탈률이다. 
   - 웹사이트의 이탈률이 높은 이유는 몇가지가 있는데, 
     1. Expectation mismatch
        - 내 웹사이트를 들어올 떄 visitor 들이 기대한것이 있을 것이다.
        - 예를 들면 지금 이 블로그(hana-dool) 를 들어오신 분들은 통계 및 데이터 분석에 대해서 배우고자 하면서 들어온사람이 많을것이다.
        - 하지만 만약 내 사이트에서 양말을 홍보하고있으면 어떻게 될까? 이는 방문자들의 Expectation과 일치하지 않기 때문에 방문자가 이탈하게 된다. 
     2. Organic search irrelevance 
        - 서치 엔진을 통해서 블로그를 들어갈 경우, 전혀 관련 없어보이는 검색어로 블로그가 뜨는 경우가 있다.
        - 예를 들면 치킨을 검색했는데, 통계관련 사이트가 뜰 수도 있다. 
        - 이런 경우는 다른 source 를 통해서 들어온 visitor 보다 이탈률이 높다.
     3. Your website SUCKS
        - 웹사이트의 구조가 전체적으로 좋지 않으면 바로 나간다. 
        - 디자인에 대해서 세세히 들어가는건 다루지 않겠다!
     4. Lack of call to action 
        - visitor 들이 그다음 Action 이 뭔지 헷갈리게 하지 말아랴 한다.
        - 예를 들어 상단의 메뉴를 누른다면, 그 아래로 주루룩 하위 카테고리가 뜨기를 기대한다. 하지만 뜬금없이 이상한 사이트로 이동한다면 Visitor 는 헷갈리는 사이트 구조때문에 적응하지 못하고 나가게 된다.
     5. Too many options 
        - 너무 많은 Obtions 를 준다면 visitor 은 제대로 집중하지 못하고 선택하지 못하게 된다.
        - 중국집에서 메뉴가 너무 많아서 오래 고민해본적 있지 않는가? 바로 그런 상황이다. (선택한 메뉴가 맛이라도 있으면 좋겠지만.. 대부분 그렇지 않은 경우가 대부분)
   - 이런 이탈율을 감소시키기 위해서는 Testing 을 통해 올바른 웹페이지 구조를 차근차근 개선해 나갈 수 있다.

4. **Make Low-risk Modificaions**

   - A/B TEST 를 통해 제일 효과가 좋은 방법을 적용할 수 있다.

   - Modificaion 의 정당한 근거를 A/B Test 가 보장해주기 때문에 Low-Risk 이다.

<br>

# How to Perform A/B test

- 잘 구성된 A/B TEST 는 심각한 문제/효과적인 개선점 을 캐치해 내어서 개선시킬 수 있다.

- 하지만 실험의 계획을 올바르게 해야 좋은 효과를 볼 수 있다. 그 과정은 다음과 같다.

1. **Resaerch**

   - A/B 테스트를 하기 전에 웹사이트가 어떻게 구동되고 있고, 이 사이트에 몇명의 사람이 오고 있으며 어떤 페이지가 많은 트레픽을 발생시키는지 등을 조사한다.
   - 또는 Survey 를 통해 사용자가 무엇을 불편해하고 있는지를 조사한다.
   - 또는 현재 유행하고 있는 웹사이트의 구조를 답습하며 어떠한 구조가 내 웹사이트에 효과적일지를 조사해본다.
   - 이렇게 먼저 Research 를 하는 이유는 A/B test 는 시간과 비용이 들어가는 실험이기 때문이다. 사전 조사를 충분히 한 이후에 가설을 잘 세워야 쓸데없는 시긴과 비용 지출을 절약할 수 잇다.

2. **Observe and Formulate Hypothesis**

   - 우리가 목표로 하는 (클릭률, 수익률...) 을 높이기 위해서 로그데이터, Research 자료 등을 조합하여 data-backend hypothesis 를 세운다. 

3. **Create Variations**

   - 다음 step 은 A/B 테스트를 실행하기 위해 현재 버전과, 변화한 버젼릐 실험을 구성하는 것이다.
   - 변화한 버젼에는 우리가 실험하고자 하는 변화를 추가한다. 
     - 버튼 색을 바꾼다던지, 결제 유형을 바꾼다던지...

4. **Run test**

   - Multivariate Testing

     - 변화가 웹 페이지의 많은 공간에서 이루어질 때
     - 그리고 그 변화의 Combinations 들을 모두 Variation 으로 추가하여 실험하는 것이다. 
     - 이를 통해 어떤 버젼이 제일  효과적인지 알 수 있다.
     - 하지만 이는 단순한 A/B test 보다 매우 복잡하다. 
     - 예를 들어서 CTA 버튼과 image 의 색상을 바꾸는 실험이 아래와 같이 구성되어있다고 하자. 총 경우의 수는 4가지로 각 사용자들은 random 으로 다른 버젼의 웹사이트를 방문하게 된다. 각각의 경우 page conversion rate 를 비교함으로서 어떤게 높은 rate 를 가지는지 알아낼 수 있다.

     ![png](/assets/images/{Others}/2_0.PNG)

   - multipage Testing

     - 많은 페이지들을 구성하여 multiple 하게 구성하여 하는 실험

     ![png](/assets/images/{Others}/2_1.PNG)

5. **Analysis**

   - A/B test 에도 Frequentist 의 접근과 Bayseian 의 접근이 있다. 
   - Frequentist 
     - Frequentist 는 기본적으로 확률을 Long term frequency 로 취급한다. 이러한 해석이 가능하려면 실험은 Random experiment 즉 재현가능한 실험이여야 한다.
     - 분석의 정확도를 위해서 많은 데이터를 수집해야한다. (testing 할 때에 데이터가 적으면, 신뢰구간이 넓어지고, testing 이 불확실해진다.) 
     - 이 방법론에서는 적용할 수 있는 방법이 제한적이라(Test 를 기반으로 하기때문에) 실험 단계에서 많은 care 가 필요하다. 
       - Test 과정에서 sample space 의 어느정도까지 기각역을 주어야 할지, UMP TEST 를 구성해야하는지, 내가 정한 기각역의 기준이 되는 Statstics의 sampling distribution 이 존재하는지/ 존재하지 않으면 Bootstrap 을 통해서 assymptotic 을  써야하는지... / 유의수준은 통상적인 0.05 가 과연 적절할지 .. 등등 고려할게 엄청 많다.
   - Baysian 
     - 이 경우에는 probability 를 개인적인 주관으로 취급한다. 
     - 베이즈는 관심있는 값에 대해 prior 로 분포를 주고 이를 데이터로 업데이트 하는 과정이기떄문에, 모든것은 분포로 나온다. 
     - 즉 Test 보다 더 많은것을 얻을 수 있으며 prior knowledge 를 inference 과정에 넣을 수 있는것도 장점이다.
   - Analysis 에 대해서는 추후에 더 다루도록 하자.

6. **Result Analysis + Deployment**

   - 누군가가 더 '좋다' 만 안다고 끝이 아니다.
   - 결과 해석은 매우 중요한데, A/B 테스트는 Continuous data 에 대한 analysis 이기 때문에 어느게 좋다는 결론이 난 이후에도 test result 를 percentage increase / confidence interval 등의 metric 을 통해 그 좋은 정도를 measure 해야한다. 

   - 그리고 마지막으로 최종 결과를 적용한다.

   ![png](/assets/images/{Others}/2_2.jpeg)

<br>

# What Can you A/B test?

- 웹사이트의 많은 부분을 바꾸어보면서 A/B 테스트를 시행할 수 있다.

1. 헤드라인 / sub-헤드라인
2. 글꼴
3. 디자인과 레이아웃
4. Navigation 등등...

<br>



# Mistakes to Avoid 

1. **Not Planning your Optimization Roadmap**
   - **Invalid hypothesis**
     - A/B Testing 시에는 테스트 전에 가설을 정한다. 이 가설을 정할때는 왜 바뀌어야하고, 어떤것을 바꿀 수 있고, 그에 따라 얻는 효과들을 미리 예측하고, 올바른 가설을 세워야 한다. 애초에 너무 허무맹랑한 가설을 세우면 Test 의 성공률이 낮아진다.
   - **Taking others word for it(다른사람의 결과를 쓰지마라)**
     - 다른사람의 웹사이트에서 버튼의 색을 초록색으로 해서 좋은 결과를 보았다고 하자. 그건 그 사람의 결과이다. 사이트를 이용하는 사람들, 시간대, 주고객층이 다르고, 이는 두 사이트의 population 이 아예 상이함을 의미한다. 그러므로 Test 의 결과가 절대로 같게 나올 수 없다.
2. **Testing too Many Elements Together**
   - 너무 많은 test 를 한번에 하는것은 어떤것이 긍정의 효과를 낳았는지 알기가 애매하다.
   - 예시로 버튼의 색, 메뉴구성, 광고 3개를 바꾸었을때 방문객이 늘었다면 이 3개중에 어떤게 긍정/ 부정의 영향을 끼쳤을까? 이는 알 수가 없다.

3. **Ignore Satistical Significance**
   - 대부분의 가설들은 실패로 돌아간다. 이런 결과에 너무 아쉬워하지 말고 (아이디어가 아쉬워서 다시 테스트해보는 행위를 하지 말라는것!) 그 결과를 받아들여야 한다.
   - 실패든 성공이든 훌륭한 Insight 가 되기 때문에 통계적 유의성을 무시해서는 안된다.

4. **Using Unbalanced Traffic**
   - 실험 설계과정에서 정한 적절한 Traffic 을 사용해야 한다. 너무 적으면 통계적으로 불안정한 결과가 나올 수 있고, 너무 높아도 쓸데없이 비용이 소모될 수 있다.
5. **Testing for Incorrect Duration**
   - 우리의 Traffic 요구량과 목표에 따라 A/B 테스트는 특정한 기간에 실시되어야 한다. 
   - 만일 너무 길거나 적은시간을 들인다면 TEST 는 유의하지 않은 결과를 낳을 수 있다.
     - 너무 짧은 시간을 사용한다면 '우연' 에 의해 그  짧은 시간에 평균적으로 트래픽이 높았을 수 있다. 그런 경우 잘못된 결론을 내게 된다.
     - 무턱대고 긴 시간을 사용하는것도 안좋을 수 있다.
       - 이는 내가 몇%의 conversion difference 를 잡아내고 싶은지, 얼마나 많은 Variation 을 Test 하고 싶은지 등에 따라 달라지는것이다.
6. **Failing to Follow an Iterative Process**
   - A/B 테스트는 반복적인 작업이다. 각각의 Test 는 이전의 결과를 토대로 생성된다. 
   - 그러므로 실패 결과를 버리지 말고 test 를 Construct 할 때에 유용하게 참고한다.
   - 또한 성공했을때에도 멈추지 말고, 꾸준히 새로운 Version 을 테스트 하며 최적을 찾아간다.
7. **Failing to consider external factors**
   - A/B 테스트시에는 대조군과 실험군이 비교 가능한 population 끼리 비교되어야 한다
   - 즉 다른날의 데이터끼리 Test 를 하게되면, 이는 population 이 다른것이므로 통계학의 Test 자체를 적용할 수 없다.

<br>



# Challenges of A/B TEST

1. **Deciding what to Test**
   - 어떤 변화가 더 긍정적인지 생각하는것은 매우 힘들다. Test 에는 비용이 발생하기 떄문에, 그 근거가 명확해야 한다. 즉 많은 research 와 Insight 가 필요한 일인 것이다.
2. **Formualating Hypothesis**
   - 적절한 Sample 을 확보하는것이 매우 어렵다. 비교 대상간 Population 이 일치하도록 섬세하게 실험을 계획해야 한다.
3. **Locking in on Sample Size**
   - 기존의 빨간색 버튼을 녹색으로 바꾸고 싶다고 하자. 그러면 많은 사람들은 실험 도중 빨간색이 유의하다는 sample size 가 나오자마자 실험을 멈추는 경우가 있는가 하면, 비용이 부담스럽다는 이유로 매우 적은 Sample size 를 선택하곤 한다. 
   - testing sample size 가 얼마나 되어야 하는지를 사전에 정해두고, 이를 지켜야 한다.
4. **Analyszing The Result**
   - 성공했던 / 실패했건 두 결과를 해석하는일은 매우 힘들다
   - Success
     - statiscally significant result 를 얻었다고 하자. 이제 승자의 방법을 적용한다. 
     - 하지만 이게 끝이 아니다. 이 test result 를 해석해야 한다. 
     - 왜 customer 이 이렇게 행동했을까? 왜 더 좋아졌을까? 혹시 외부변수가 개입한것은 없었을까?, 지금 시기에만 이런 결과가 나오지 않을까? 등을 고려해야 한다. 
   - Fail
     - 실패한 경우라도, 다음번에는 성공적인 실험을 위해 어느점때문에 실패하였는지 등을 분석하며 배워야 한다.
5. **Not change anything**
   - 실험 도중에는, 우리가 의도한 변화 말고는 아무 변화도 없어야 한다.

<br>

# Reference 

- https://www.youtube.com/watch?v=ONM0dWEsJXs #SKplanet Tacademy
- https://vwo.com/blog/why-your-bounce-rate-is-high-and-how-to-fix-it-top-6-reasons/
- https://vwo.com/ab-testing/?utm_source=google&utm_medium=paid&utm_campaign=mof_ee1_search_category_tof_ab-testing_generic_skag&utm_content=498195403571&utm_term=ab%20testing&gclid=Cj0KCQiAhP2BBhDdARIsAJEzXlGnxPJc2DLtP0ZfOc9qhOZcTg46nTMRO-cZKWpIak5C78Rusjm1c3IaAvjvEALw_wcB#what-is-a-b-testing





