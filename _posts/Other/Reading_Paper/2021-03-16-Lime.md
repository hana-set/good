---
title:  "Lime"
excerpt: "Why Should I Trust You? : Explaining the Predictions of Any Classifier"
categories:
  - Reading_Paper
tags:
  - 1
last_modified_at: 2021-03-17

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

# <center><font size="20"> intro </font></center>

사실 이 논문은 홈쇼핑 비콘데이터 하던때에, 예측력을 위해서 딥러닝 모델을 쓰긴 썻는데 해석하는데에 어려움이 있어서 interpretable machinelearning 에 대해서 찾아보다가 알게된거라 읽은지 시간이 오래 지난 논문이다. (그때 정리한 파일이 한글파일이라서... 어쩔 수 없이 png 로 변환 후에 사진으로 올려본다.) 



<BR>

# <center><font size="20"> 내용</font></center>

![png](/assets/images/Paper/Lime_han_01.png)

![png](/assets/images/Paper/Lime_han_02.png)

![png](/assets/images/Paper/Lime_han_03.png)

![png](/assets/images/Paper/Lime_han_04.png)

![png](/assets/images/Paper/Lime_han_05.png)

![png](/assets/images/Paper/Lime_han_06.png)

![png](/assets/images/Paper/Lime_han_07.png)

![png](/assets/images/Paper/Lime_han_08.png)

![png](/assets/images/Paper/Lime_han_09.png)

![png](/assets/images/Paper/Lime_han_10.png)

![png](/assets/images/Paper/Lime_han_11.png)

![png](/assets/images/Paper/Lime_han_12.png)



<br>

# <center><font size="20"> Review </font></center>

- 사실 '국소적인 부분에서 Linear' 하다라는 가정이 핵심가정인데, 이를 뒷받침할만한 증거가 없어서 약간 아쉽다.
- 그리고 국소적인 해석에 대한 내용이 주여서 , 나중에 전체 데이터의 해석을 위한 Submodular pick 이라는 방법을 제시하긴 하는데 이도 결국 '이렇게 하면 어느정도 대표성이 보장된다고 볼 수 있지 않을까?' 정도의 느낌이고 Justification 이 약한것 같다.
- 블랙박스 모델의 안을 해부하는것이 아닌, 블랙박스 모델이 내뱉는 결과들의 파편을 모아모아 어찌저찌 해석하려는 노력을 볼 수 있었던 논문. 나도 어쩔 수 없이 이 방법으로 모델해석을 하려 했지만 별로 좋은 결과는 얻지 못했었다. 