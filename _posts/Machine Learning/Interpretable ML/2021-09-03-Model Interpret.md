---
title:  "What is Interpretability?"
excerpt: "해석력은 어떤것을 의미하는가?"
categories:
  - Interpretable_ML
tags:
  - 1
last_modified_at: 2021-09-01

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

<br>

# Intro

- 기계학습 모델을 해석할떄에, 이것을 사람이 어떻게 해석할 수 있는지에 대해서는 많은 방법이 존재합니다. 
- 그 이유는 어떤것을 기준으로 하는지에 따라서 모델을 해석할 수 있는 여부가 달라지기 떄문입니다.

<br>

# 해석방법 : Intrinsic vs Post-hoc

## 사전(Intrinsic) 해석

- 모델을 단순하게 만듦으로서, 모델을 사전 해석할 수 있습니다.  즉 모델링 그 자체로 해석이 가능합니다.
- 대표적으로는 Linear regression 이 가능합니다. 
  - 변수의 크기는, 곧 그 변수의 중요도가 될 수 있습니다
  - 또한 p-value 를 통해서 그 변수가 얼마나 유의한지도 살펴볼 수 있습니다.
- 주로 모델의 내재적 구조 정보를 이용하여 분석하게 됩니다.
- 사전 해석법은 비교적 모델이 단순한 linear regression / Disicion Tree 등에 이용됩니다.. 

## 사후(Post-hog) 해석

- 사후 해석법은 모델의 종류에 상관 없이, 그 모델의 Input 과 Output 을 살펴보면서 해석하게 됩니다.
- 사후 해석법은 모든 모델에 대해서 적용이 가능합니다.

<br>

# 해석 방법 : Global vs Local

- 모델을 어떤 범위에서 해석하는지에 따라 해석 방법을 다르게 할 수 있습니다. 

## Local 해석

- 각 데이터 Point 마다 해석을 하는 방법은 Local 해석이라고 합니다. 
- 예시로 , '키 180cm , 몸무게 100kg 인 경우 소득을 30만달러라고 예측했는데 그 이유가 궁금해!' 같은 경우에 사용됩니다. 
- 이런 Local 해석은 전체 모델의 해석 결과보다 '특정한 Point' 에 집중하여 해석하기 떄문에, 특정 데이터 해석에 대해서는 Global 해석보다 정확합니다. 

## Global 해석

- 전체 데이터를 아우르는 해석입니다.
- 예를 들어서 대체로 이 모델에서 어떤 변수가 어떤 작용을 하였는지를 나타내는 설명입니다. 
- 데이터를 전반적으로 이해하는데에는 도움을 주지만, 특정 경우에 대해서는(Local) 설명력이 안좋을 수 있습니다.

<br>

# 해석력의  평가

- 위에서 우리는 해석 방법에 따라서 여러지 '해석' 이 있음을 알았습니다.
- 우리는 과연 특정한 모델에서 여러가지 '해석' 력을 어떻게 평가할 수 있을까요? 

## 알고리즘 투명성(Algorithm Transparency)

> 이 알고리즘은 어떻게 모델을 생성하는가?

- 알고리즘 투명성은, 작동 원리를 단순히 알 수 있다는것이 아니라, 이 모델이 현제 어떻게 예측하고 있고 어떤 흐름으로 각 변수가 영향을 주는지를 안다는 것입니다. 
- DNN 모델의 경우, 역전파 알고리즘으로 어떻게 모델이 학습하는지는 알 수 있지만 수백만개의 노드가 어떤 영향으로 어떻게 예측이 이루어지는지를 모두 알기는 어려울 것입니다.
  - 이러한 경우 알고리즘이 불투명하다고 합니다.
- linear regression 의 경우 최소 제곱법이라는 Fitting 원리를 이해할 수 있으며 어떻게 예측이 되는지도 모두 알 수 있습니다. 







