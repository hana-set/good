---
title:  "KDE"
excerpt: "커널 추정을 통한 데이터 분포추정"
categories:
  - Stat_Non_Parametric
tags:
  - 1
last_modified_at: 2021-08-21

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

<br>

- https://darkpgmr.tistory.com/147?category=761008 의 게시글이 너무 잘 설명해서 이 글의 서술을 대부분 따랐습니다.

# 밀도추정 (Density Estimation)

- 데이터는 어떤 변수가 가질 수 있는 다양한 가능성 중의 하나가 현실 세계에 구체화된 값이다. 
- 그리고 우리는 이렇게 관측된 데이터들을 통해 그 변수(random variable)가 가지고 있는 본질적인 특성을 파악하고자 노력한다.
- 그러나 하나의 데이터는 변수의 일면에 불과하기 때문에 변수의 진면목을 파악하기 위해서는 많은 수의 데이터가 필요하다. 
- 그리고 이렇게 얻어진(관측된) 데이터들의 분포로부터 원래 변수의 (확률) 분포 특성을 추정하고자 하는 것이 density estimation(밀도추정)이다.

<br>

#Parametric vs. Non-parametric 밀도추정

- Parametric 밀도추정은 미리 pdf(probability density function)에 대한 모델을 정해놓고 데이터들로부터 모델의 파라미터만 추정하는 방식이다. 
  - 예를 들어, '일일 교통량'이 정규분포를 따른다고 가정해 버리면 관측된 데이터들로부터 평균과 분산만 구하면 되기 때문에 밀도추정 문제가 비교적 간단한 문제가 되어 버린다.

- 현실 문제에서 이렇게 모델이 미리 주어지는 경우는 많지 않으며 분포의 모델을 미리 안다는 것은 너무나 강한 혹은 사치스러운 가정일 수 있다. 
- 이 경우 어떠한 사전 정보나 지식 없이 순수하게 관측된 데이터만으로 확률밀도함수를 추정해야 하는데 이를 non-parametric density estimation라 부른다.
- Non-parametric 밀도추정의 가장 간단한 형태가 바로 히스토그램(histogram)이다. 즉, 관측된 데이터들로부터 히스토그램을 구한 후 구해진 히스토그램을 정규화하여 확률밀도함수로 사용하는 것이다.

![png](/assets/images/Stat/41_1.png)

<Br>

# Kernel Density Estimation (커널 밀도 추정)

- 앞서 non-parametric 밀도추정의 가장 단순한 형태가 히스토그램(histogram) 방법이라고 했는데, 이 경우 아래와 같은 문제점을 가집니다.
  - 히스토그램 방법은 bin의 경계에서 불연속성이 나타난다는 점, 
  - bin의 크기 및 시작 위치에 따라서 히스토그램이 달라진다는 점, 
  - 고차원(high dimension) 데이터에는 메모리 문제 등으로 사용하기 힘들다는 점

- Kernel Density Estimation (커널 밀도 추정) 방법은 non-parametric 밀도추정 방법 중 하나로서 커널함수(kernel function)를 이용하여 히스토그램 방법의 문제점을 개선한 방법이다.

## Kernel 함수란?

- 먼저, 커널함수(kernel function)에 대한 이해가 필요한데 수학적으로 커널함수는 원점을 중심으로 대칭이면서 적분값이 1인 non-negative 함수로 정의된다.
  -  가우시언(Gaussian), Epanechnikov, uniform 함수 등이 대표적인 커널 함수들이다.

![png](/assets/images/Stat/41_2.png)

## 추정

- 다시 KDE(Kernel Density Estimation, 커널 밀도 추정)로 돌아가서 x를 변수(random variable), x1, x2, ..., xn을 관측된 샘플 데이터, K를 커널 함수라 하자. 
- 이 때 KDE에서는 랜덤 변수 x에 대한 pdf(확률밀도함수)를 다음과 같이 추정한다.

![png](/assets/images/Stat/41_3.png)

- 식 (4)에서 h는 커널(kernel) 함수의 bandwidth 파라미터로서 커널이 뽀족한 형태(h가 작은 값)인지 완만한 형태(h가 큰 값)인지를 조절하는 파라미터이다. 
- 수식적으로 보면 어렵지만 이를 직관적으로 이해하면 다음과 같다.

![png](/assets/images/Stat/41_4.png)

- 히스토그램을 이용한 밀도추정 방법과 KDE 방법을 비교해 보면, 히스토그램 방법은 이산적(discrete)으로 각 데이터에 대응되는 bin의 값을 증가시킴으로써 불연속성이 발생한다,
- KDE(커널밀도추정) 방법은 각 데이터를 커널 함수로 대치하여 더함으로써 그림 4 오른쪽 그래프와 같이 smooth한 확률밀도함수(pdf)를 얻을 수 있는 장점을 갖는다.

<br>

# Hyperparameter

![png](/assets/images/Stat/41_5.png)

- 실제 KDE를 사용할 때, 중요한 이슈는 어떤 커널 함수를 사용할지와 커널 함수의 bandwidth 파라미터인 h 값을 어떻게 잡을지이다. 
- 위키피디아에 의하면 가장 최적의 커널함수는 Epanechnikov 커널이며 계산의 편의상 Gaussian 커널함수도 많이 사용된다고 한다. 
- 그리고 Gaussian 커널함수를 사용할 경우 최적의 bandwidth 파라미터 값은 다음과 같다고 한다.

![png](/assets/images/Stat/41_6.png)



Note) 다시한번 이 글은 다크프로그래머 님의 글을 가져왔음을 밝힙니다. (이 글보다 더 잘 정리할 자신이 없어서 그대로 옮겨왔습니다.)
