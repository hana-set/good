---
title:  "p_value 3"
excerpt: "p Value 시리즈 3 : 역사와 그 오용"
categories:
  - Stat
tags:
  - 1
last_modified_at: 2021-08-12

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

<br>

- https://www.facebook.com/buckeyestatfisher/posts/302726940668694/ 님이 너무 잘 정리해놓으셔서 , 이 서술을 대부분 가져오고 제 해석을 덛붙인 글입니다.

- 진짜 p-value 는 악질인게 , 배워도배워도 끝이 없네요;;
- 좀 더 알아본 결과... 약간 이 글은 너무 '통계에 매몰된' 느낌이 있긴 한것같더라구요. Neyman Pearson 이여도 p-value reporting 하는거 정도야... 봐주죠..

# Intro

- P값을 위주로 한 통계적 가설검정법 - 흔히 영가설 유의성검정 절차 Null Hypothesis Significance Testing, NHST 이라고 부릅니다 - 은 얼핏 보기에는 하나의 일관적인 이론적 프레임같아 보입니다. 
- 하지만 역사적 관점에서 NHST는 두 양립 불가능한 접근법의 혼종이라 볼 수 있습니다. 사실 매우 끔찍한 혼종이죠. 그 이유는 차차 아시게 될 겁니다. 
- 아무튼 그 두 접근법은 현대 통계학을 정립하는 데 결정적 기여를 한 세 사람, 즉 피셔 R. A. Fisher, 네이만 Jerzy Neyman, 피어슨 Egon Pearson 에 의해 생겨났습니다. 지금부터 하나씩 차차 설명하도록 하겠습니다.

# 1. 유의성 검정

- 첫째는 '유의성검정' significance testing 이라는 것인데 피셔 경이 고안한 것입니다. P-value, 유의수준 같은 용어는 바로 이 접근법에서 유래된 것입니다. 
- 유의성검정 방식의 주된 목적은 영가설 null hypothesis 을 테스트하는 것입니다. 영가설은 연구자가 검증하고자 하는 가설로, 귀무가설, 즉 "어떤 효과가 없다" 등의 형식입니다. 
- 이를테면 "처치효과가 정확히 1이다" 라든가 "집단 간 차이가 0.5다" 라는 식으로 말이죠. 영가설을 검증하기 위해 연구자는 P값을 계산하는데, 이것은 이미 잘 아시는 바와 같이 "영가설 하에서 관측된 자료 이상으로 극단적인 자료가 관측될 확률" 로 정의됩니다.
- 여기서 P값이 작다는 것은 연구자가 얻은 자료가 영가설 하에서는 관측되기 힘들다, 다시 말해 영가설에 의해 잘 설명되지 않는다는 것으로 해석됩니다. 
- 즉 P값은 영가설에 대한 반증의 정도를 나타냅니다. P값이 충분히 작으면 연구자는 영가설을 기각하는데, 그 기준이 바로 '유의수준' level of significance 의 개념입니다.
- 그리고 여기서 그 악명높은 0.05의 기준이 등장하게 되죠. 피셔는 0.05를 유의수준의 한 예로 제시하면서, 언제나 유의수준이 0.05일 필요는 없다는 말도 함께 덧붙였습니다. 
- 그는 유의수준은 연구자의 사전지식, 연구의 배경 등에 의해 유연하게 조절되어야 함을 역설했지만, 후대에 이런 훈계는 어느 샌가 잊혀지고 0.05라는 관행적 유의수준만 남아 이어지게 된 것입니다.
- 여기까지가 유의성검정의 대강의 개요입니다. 한 가지 중요하게 눈여겨봐야 할 것은 피셔의 유의성검정 방법에서는 대안가설 alternative hypothesis 이라는 것이 전혀 등장하지 않는다는 것입니다. 
- 사실 당연한 것이, 피셔가 생각한 유의성검정의 목적은 단일 가설을 테스트하는 것이었기 때문입니다. 
- 다른 가설은 전혀 생각할 필요가 없죠. P값이 유의수준보다 작으면 영가설을 기각하고, 그렇지 않으면 판단을 보류하는 것, 그뿐입니다. 
- P값이 작다고 해서 대안가설을 받아들이는 따위의 행위는 피셔에게는 받아들일 수 없는 것이었습니다.
-  또 한 가지 눈여겨볼 것은 P값은 단일 연구에서 획득한 자료가 영가설을 반증하는 정도를 수치화한 것으로, 연구의 반복적 수행을 전제하지 않는다는 점입니다. 
- 이는 지금부터 소개할 네이만-피어슨의 접근법과 확연히 다른 것으로, 이들은 "반복" 이라는 개념을 핵심적으로 생각했습니다.

# 2. 가설 검정

- 둘째는 '가설검정' hypothesis testing 이라는 것인데 이것은 네이만과 피어슨에 의해 고안되었습니다. 
- 알파, 베타, 검정력, 기각역, 대안가설 등의 용어는 전부 유의성검정이 아닌 이 쪽에서 온 것입니다. 
- 특히 이들의 관심사는 개별 연구의 증거를 평가하는 것이 아니라 반복적인 의사결정을 내리는 상황이었습니다. 
- 즉 가설검정을 계속 할 때, 그 중 얼마만큼의 비율에서 오류를 저지르느냐? 그리고 그 오류를 특정 값 이하로 통제하려면 어떻게 해야 하느냐? 이런 질문들이 네이만과 피어슨이 던진 질문들입니다. 
- 여기서 독자 여러분은 이미 피셔와 네이만-피어슨 접근법의 근본적 차이를 눈치채셨을 것입니다.
- 피셔는 단일 연구에서 획득한 증거를 평가하는 데 관심이 있었던 반면, 네이만-피어슨은 그런 것에 관심 없이 전반적인 오류 확률을 통제하는 데 관심이 있었습니다. 
- 그리고 이 목적의 차이가 두 접근법 사이의 구체적인 차이로 이어졌습니다.네이만과 피어슨은 피셔와는 다르게 하나가 아닌 두 가설 중 어느 것을 채택할 것이냐 하는 데 관심이 있었습니다. 
- 즉 이들은 영가설 뿐 아니라 대립가설 alternative hypothesis도 고려했습니다. 즉 대립가설은 네이만-피어슨 접근법의 고유한 개념이며 피셔의 유의성검정 절차에는 등장하지 않는 개념입니다. 
- 여기서 '채택'이라는 말에 주의해야 하는데, 이는 채택한 가설이 진리냐 아니냐와 관계없이 그냥 실용적 목적으로 선택한다는 것을 의미합니다.
- 이는 이들의 접근법이 과학적 가설을 평가하기 위한 것이라기보다는 단지 의사결정의 방법 decision-theoretic framework 으로 이해되는 이유이기도 합니다.
- 이들은 특히 두 종류의 오류에 관심이 있었는데, 여러분들도 이미 잘 아시는 1종/2종 오류입니다. 1종오류는 영가설이 참인데 대립가설을 채택하는, 2종오류는 대립가설이 참인데 영가설을 채택하는 오류죠. (이 오류들 자체가 유의성검정에서는 없는 개념입니다.) 
- 네이만과 피어슨은 이 두 오류의 확률들을 특정 값 이하로 통제하는 방법을 고안했습니다. 여기서 알파와 베타라는 개념이 등장하는데, 알파는 허용 가능한 1종오류의 확률, 베타는 허용 가능한 2종오류의 확률을 일컫습니다.
- (물론 여기서 "확률"이라 함은 반복적인 실험을 하는 상황을 가정합니다.) 알파를 통제하기 위해서 연구자는 영가설을 기각하는 데 필요한 최소한의 통계치 값을 설정하는데, 이것이 "임계치" critical value 또는 "기각역" critical region 이 됩니다. 
- 그리고 베타를 통제하기 위해서는 표본 크기 sample size 를 결정하는데, 여기서 검정력 power 의 개념이 등장합니다. 검정력은 1에서 베타를 뺀 값으로, 대립가설이 옳을 때 영가설을 기각할 확률을 의미합니다. 
- 특정 검정력을 위해 필요한 표본 크기를 계산함으로써 연구자는 베타 값을 통제할 수 있습니다. 
- 그런데 검정력 또한 네이만-피어슨의 접근법에서만 등장하는 개념으로, 피셔의 유의성검정에서는 대립가설이 존재하지 않으니 당연히 검정력이라는 개념도 무의미하겠죠.
- 이렇게 알파와 베타를 통제하기 위한 의사결정 규칙을 세웠습니다. 그러면 연구자가 해야 할 일은 사전에 영가설, 대립가설, 알파, 베타, 표본 크기를 결정하고, 데이터를 확보한 뒤, 그로부터 계산한 통계치가 임계치보다 크면 영가설 기각/대립가설 채택, 아니면 영가설 유지/대립가설 비-채택을 결정하는 것입니다. 
- 네이만-피어슨 접근법에서는 따라서 P값 같은 것은 보고할 필요가 없습니다. 물론 영가설, 대립가설, 알파, 베타, 표본크기는 모두 보고해야 하겠죠.
- 반대로 피셔의 유의성검정 접근법을 (딱딱하게) 따른다면 영가설과 P값만 보고하면 될 것입니다. 표본크기 정도는 부가적으로 보고할 수 있겠네요. 하지만 대립가설, 알파, 베타는 보고해서는 안 됩니다. 
- 예를 들어 연구자가 one sample z-test에서 Z=2를 관측했습니다. 
  - 유의성검정을 했다면 $H_0: \mu=0, P-value=2*(1-pnorm(2))=0.046$, 유의수준 0.05,
  - 가설검정을 했다면 결정: 영가설 기각, $alpha=0.05, beta=1-0.609, H_0: \mu=0, H_1: \mu=0.5, N=20$ 이렇게 보고할겁니다. 
- 자, 어떻습니까? 지금까지 설명을 잘 따라오신 독자라면 유의성검정과 가설검정은 완전히 다른 목적을 위해 고안된 완전히 다른 절차라는 것을 눈치채셨을 겁니다. 
- 실제로 피셔와 네이만-피어슨은 통계분석에 대한 이런 근본적인 견해차 때문에 논쟁을 거듭했으며, 서로 심하게 반목했다는 사실은 이미 잘 알려져 있습니다. 

# 현대에서의 P-value

- 그런데 어쩌다가 이 두 접근법이 갑자기 하나인 것처럼 둔갑하게 되었을까요? 그것은 통계학이 다른 분야들에 과학 연구의 방법론으로 수용되면서부터입니다. 
- 사실 이 두 접근법 사이에는 (불행하게도) 통하는 점이 하나 있었는데, 그것은 바로 수학적으로는 두 접근법이 동일한 결과를 산출한다는 것이었습니다. 
- 즉 유의수준과 알파 값이 동일한 경우, 한 쪽에서 영가설이 기각되면 다른 한 쪽에서도 영가설이 기각된다 (또는 그러해야 한다) 라는 것이죠. 
- 물론 이것이 대안가설의 수용을 의미하는지는 두 접근법에서 완전히 다릅니다. 하지만 이런 차이점들이 통계학 비전문가들에 의해 간과되면서, 이런 단순한 수학적 유사성이 두 접근법의 융합이라는 매우 이상한 결과로 이어지게 되었습니다. 
- 즉 유의수준과 알파가 동일한 것으로 이해되고, 영가설의 기각이 언제나 대안가설의 수용인 것처럼 잘못 받아들여지면서, 우리가 배우고 있는 현대적 형태의 "끔찍한 혼종"과도 같은, 이상하고 근본없는 통계학이 탄생하게 된 것입니다. 
- 그리고 오늘날도 우리는 여전히 이것을 배우고, 또 전수하고 있습니다. 이것이 근본적으로 양립 불가능한 접근법이라는 것을 모르는 채 말이죠. 하지만 그 철학적 근거는 사실상 전무하다고 할 수 있을 것입니다. 
- 어쩌면 이 두 접근법이 완전히 융합된 것처럼 보이게 하기 위해서라도 통계학 교과서에서는 과거의 역사를 생략해야 하는지도 모르겠습니다. 하지만 우리가 영가설 유의성검정 방식이 탄생하게 된 역사를 이해하는 순간, 그것이 말이 안 된다는 사실은 분명해집니다. 
- 아마 피셔, 네이만, 피어슨이 다시 살아온다면 지금 우리가 보고 있는 통계학 교과서를 보고 매우 분노했을 것입니다. 그리고 아마 찢어버리려고 했겠죠. 이토록 반목하던 이들의 대립적인 관점이 쥐도새도 모르게 융합되어 전승되었다는 점은 참으로 역사의 아이러니라 하지 않을 수 없습니다. 
- 그리고 이것을 올바르게 이해하는 것은 우리가 지금 영가설 유의성검정이라는 도구를 갖고 무엇을 하고 있는지, 그 문제점을 어떻게 해결할 것인지를 생각하는 데도 매우 중요하다고 할 것입니다.

# 비교 그림

![png](/assets/images/Stat/35_1.png)

![png](/assets/images/Stat/35_2.png)

# Reference

- https://www.facebook.com/buckeyestatfisher/posts/302726940668694/
- https://stats.stackexchange.com/questions/23142/when-to-use-fisher-and-neyman-pearson-framework
- https://ekja.org/upload/pdf/kjae-69-121_ko.pdf

- , J. W. (2015). Null hypothesis significance tests. A mix-up of two different theories: the basis for widespread confusion and numerous misinterpretations. Scientometrics, 102(1), 411-432.
- [https://link.springer.com/article/10.1007/s11192-014-1251-5](https://link.springer.com/article/10.1007/s11192-014-1251-5?fbclid=IwAR2jEzY4PsWhuT1nQF2lleAW3n4F3YtDG1KjXLqH1hfA0iA323obATKvRek)Gigerenzer, G. (2004). Mindless statistics. The Journal of Socio-Economics, 33(5), 587-606.
- [https://www.sciencedirect.com/.../pii/S1053535704000927](https://www.sciencedirect.com/science/article/pii/S1053535704000927?fbclid=IwAR208g69G6mZT2AgF0DkkGf0RBtHUWBfADQdIoeM5GbK5GZ15-TsLfq3ii4)

