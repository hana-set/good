---
title:  "p-value 2"
excerpt: "p 값 시리즈 2 : 어떻게 계산되는가?"
categories:
  - Stat
tags:
  - 1
last_modified_at: 2021-07-02

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

# P-value

> 데이터가 대립가설 방향쪽으로 얼마나 편향되어있는지를 나타내는값

- 위와 같이 한마디로 요약 가능한게 P-value 이다. 
- 그런데 위같이 간단한 개념 저변에 깔린 이론들과 맥락은 어마어마하기 떄문에 차근차근 같이 풀어보자.
- 개인적으로 '개인이 얼마나 통계학을 깊게 바라보는가?' 를 알고싶을떄, 나는 무조건 P-value 를 물어보는 편이다.. 

<br>

# $\alpha$ 유의수준

> 유의수준(제 1종오류) 이란, 귀무가설이 맞을떄에 기각할 확률이다. 

- 통계의 '검정' 을 논할떄에, $\alpha$ = 0.05 에서 p-value 는 0.04 니까 ..... 등의 말을 들어보았을 것이다.
- 여기서 드는 의문이 있다. 

> Q. 아니, 유의수준도 결국 에러인데 이걸 왜 0.05 로 설정해요? 0.0001으로해요! 

- 유의수준이란건 "의심하는 정도" 를 나타내는것이다.
- 유의수준이 엄청 작다는것은, 웬만하면 귀무가설만 고르겠다는 의미이다. 즉 귀무가설이 틀린 경우, 너무 작은 유의수준을 가질 경우, 어떠한 증거가 나와도 귀무가설만을 고수할 것이다. 
  - 동전던지기 예시에서 앞면이 100번 나와도 "나는 이 동전이 공평할거라 믿어!" 라고 고집부리는거랑 똑같은것이다..

<br>

# $\beta$ 2종오류

> 2종 오류란 , 대립가설이 맞을때에, 귀무가설을 선택할 확률이다.

- 위 1종오류와 반대되는 오류이다. 
- 이 값이 한없이 작다는건, 대립가설만을 선택한다는것이고 위와 같은 에러를 불러 일으킬 것이다. 

<br>

<br>

# 기각역

- 기각역이란, 데이터가 어떤 값을 가질때에 귀무가설을 기각하는 영역이다.
- 즉 일종의 Decision Rule 을 영역으로 표현한 것이다.
  - EX) $\bar{X} >3$ 이면 귀무가설을 기각한다.

<br>

# Hypothesis Testing

- 가설 검정이란 다음과 같은 Flow 를 따른다고 할 수 있다.
  - 알고싶은 값의 세상을 Parameter Space 로 끌어내린다. (ex 평균을 Normal 이라 가정하는것)
    - 이제 다양한 분포들은 , 몇개의 Parameter 로 요약된다. 즉 수학적으로 계산이 편해진다! 
    - 예시로 Normal 분포의 세상은 $\mu , \sigma$ 즉 $R*R^+$  space 로 mapping 이 됨
  - Parameter Space 를 양분하여 (parameter 로 표현되기 때문에 양분이 가능) $H_0$, $H_1$  을 나눈다. 
  - Sample Space 양분하여 기각역, Acceptance Region 을 나눈다.
    - Sample space 란, 우리가 Testing 으로 사용하고자 하는 검정 통계량이 가지는 값의 세상이다.
    - 예시로 $\bar{X}$ 를 통계량으로 하고,  $\bar{X} \le 0$ 을 기각역으로 할 수 있을것이다.
    - 이는 Decision Rule 을 정하는것으로 이해할 수 있다.
  - 나눈 영역을 서로 매칭한다. 

> 가설검정이란 Parameter space 와 Sample space 를 양분해 매칭하는 행위

```
ex) 
제조사의 과자 무게가 100g인지 아닌지 검정하고자 한다.
1. 데이터가 Normal 을 따른다고 가정하자. 
- 이는 과자 무게가 따르는 복잡한 세상을 단순화한것.
- 단 2개의 파라미터로 세상을 단순화 하게된다.

2. Parameter space 를 양분한다. 
- 귀무가설(과자무게는 100g이야!) : mu = 100 의 영역 
- 대립가설(과자무게는 100g 아니야!) : mu != 100 의 영역 

3. Sample Space 를 양분한다. 
- 이때에 검정통계량을 n=5 인 Sample mean 으로 잡았다 하자.
- 95 < mean(X_i) < 105 : Accept Region
- other wise : Reject Region

4. 나눈 영역을 매칭한다. 
- Accept Region 와 H_0
- Reject Region 와 H_1

# 이제 Sample 을 뽑았을때에, 
1.검정통계량이 Accept region 안에 들어가면 H_0 선택
2.검정통계량이 Reject region 안에 들어가면 H_1 선택
```

<br>

# Decision rule

- 위 경우, 대립,귀무가설을 세우는거야 어떻게 하겠는데, Sample space 를 양분할때에가 문제가 된다. 
- 대체 '어떻게' 나눌 수 있을까? 

- 이 경우에 필요한게 바로 1종, 2종 오류이다. 

- 일반적으로 다음과 같은 Decision rule 을 가지는게 이상적이다.
  - 검정통계량이 귀무가설쪽 같으면 귀무가설 선택
  - 검정통계량이 대립가설쪽 같으면 대립가설 선택 
- 위의 Decision Rule 을 만들기 위해서, '귀무가설을 가정하였을 떄에 검정통계량이 따르는 분포' 를 이용하게 된다. 
  - 귀무가설($\mu=0$) 가정시에 검정통계량 $\bar{x}$ ~ N(0,1) 의 분포를 따른다 하자.
  - 검정통계량이 1.96 보다 크거나, -1.96보다 작은 값을 가지게 된다면, 이는 귀무가설을 가정했을때에는 나오기 힘든 값이다.
  - 검정통계량이 -1.96~1.96 이라면, 귀무가설을 가정할 떄에도 어느정도 납득할만한 경우이다. 
  - 즉 Reject region 은 $\mid\bar{x}\mid \ge1.96$ 가 되고, 이게 Decision rule 이 된다.

<br>

# 어쩔수 없는 Error

- 하지만 위의 Decision rule 에서 이상한것을 눈치채지 못했나요? 
- 바로.. '귀무가설이 사실이여도 1.96 이상의 값을 가질 수 있다!' 라는 것입니다. 
- 즉.. 완벽한 Testing 을 만든다는건 불가능하다는것입니다. 에러가 불가피합니다.
- 선택의 가짓수가 2개 이므로 , 아래와 같이 2개의 에러가 생기게 됩니다. 
  - 귀무가설이 맞는데 대립가설을 택할떄의 에러 (1종오류)
  - 대립가설이 맞는데 귀무가설을 택했을떄의 에러 (2종오류)

- 위와 같은 에러의 값을 조절하면서 Decision Rule 을 만들어야 하는것이죠.
- 1종오류 , 2종오류는 trade off 관계에 있기 떄문에 적절히 잘 조절해야 합니다. 

<br>

# $\alpha$ 1종에러 고정

- 에러를 조절할떄에 1종오류와 2종오류를 가변적으로 조절할 수 있습니다.
- 이 경우 주로 1종오류를 먼저 선택하는데 그 이유는, 테스팅을 보수적으로 하기 위해서입니다.

- 일반적으로 테스팅의 목적은 '귀무가설의 기각' 입니다. 
  - 신약을 개발했을떄, 내 신약이 기존것보다 더 효과가 있으면 좋겠어! 
  - 이 경우 귀무가설 : 효과없음 / 대립가설 : 효과있음 이 됩니다. 
- 그러므로 테스팅은 보수적으로 되어야 합니다.
  - 귀무가설이 맞는데 대립가설을 선택하는게 심각할까요? (2종 에러)
  - 대립가설이 맞는데 귀무가설을 선택하는게 심각할까요? (1종에러)
  - 귀무가설이 '일반적으로 통용되던 사실' 임을 가정하면 2번째 에러가 더 심각합니다.
- 즉 심각한 1종에러를 미리 Fix (0.05) 하고 나서 실험을 진행하는 것입니다. 

<br>

# $\beta$ 2종오류 조절

- 2종 오류의 경우는 어떻게 될까요?
- 귀무가설을 사실로 받아들임에 따라서, 검정통계량의 분포가 정해집니다.
- 이 분포에서, 기각역을 1종오류가 0.05 가 되도록 설정합니다.
- 하지만 그 영역은 매우 많을것입니다. 
  - [-3,5] , [-10,0] 등...

- 위 영역중에서 2종오류를 최소화 (또는 검정력(1-$\beta$)을 최대화) 하는 Reject Region 을 선택하게 됩니다. 

![png](/assets/images/Stat/10_2.png)

- 위는 위 Frame work 를 매우 단순화한 그림입니다. 
- 각 분포는 '검정통계량' 의 분포입니다. 
- $H_1 = a$ 처럼, point 일때의 그림입니다.  

<br>

# 드디어 p -value

- 드디어 다시 p-value 로 왔습니다.

> 데이터가 대립가설 방향쪽으로 얼마나 편향되어있는지를 나타내는값

- 이제는 Hypothesis Testing 의 프레임워크를 어느정도 알았으니 정확한 값은 다음과 같습니다.

> 귀무가설이 맞다는 가정 하에서 지금 검정통계량보다 대립가설쪽으로 극단적인 값이 나올 확률

![png](/assets/images/Stat/10_1.png)

- p-value < 유의수준 이면 귀무가설을 기각하게 됩니다. 
- 사실 p-value 로 정하는것이나, 기각역으로 정하는것이나 같은데요, 편의상 p-value 를 더 선호합니다.
- 옛날에는 p-value 계산이 너무 끔찍해 기각역으로 했다고 합니다.
  - 당연히 기각역으로 하게되면 더 쉽습니다. 정확한 값을 구할 필요가 없기 떄문이죠.

<br>

# 주저리주저리

- 사실 ... p -value 의 병폐도 있고... 
  - 데이터 막 선택하면서 0.05 이하인거 선택할수도..
    - 데이터를 임의로 선택할 수 있다는거..
  - p-value 는 P(H$\mid$D) 가 아니라 P(D$\mid$H) 임..
    - 사람들은 전자로 이해하는데 (p-value 가 0.05 면 5% 로 귀무가설이 맞는거야? ) 이게 아님.
    - 그냥 '데이터' 가 H_0 하에서 그정도의 확률을 가진다는것.. 
  - 이해하기가 너~무 힘듦
    - 지금 위 프레임워크를 다 이해해도, 아직 더 남아있음... 
    - 위는 그냥 맛보기정도? 임....  
  - 데이터 수집과정에 따라서 p값이 변하는것.. 
  - 등등등....
- 베이지안에서 p-value 는 왜 없는가? 
  - 베이즈는 '모수의 분포' 그 자체가 Inference 임.. 사실 더 논의할것도 없음
  - Freq 는 parameter 를 constant 로 보는탓에 맞다 아니다가 되기때문에 일어나는 병폐..
    - 그래서 '판단 기준' 이 필요하고, 그에따라서 P-value 를 기준으로 삼게되는것.
- 할말이 엄청 많은데... 다음 시리즈로 넘길게요..

